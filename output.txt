agneticResonanceImaging(MRI)isacommonlyusedimagingtechniquethatisnon-invasiveanddoesnotuseionizingradiation,makingitsafeforimagingsofttissues.However,thelengthyscantimerequiredforMRIcanlimititsapplication,particularlyforpatientswhocannotremainstillforextendedperiodsorrequireurgentresults.Toaddressthesechallenges,researchersaredevelopingfasterMRItechniquesthatcanproducehigh-qualityimagesinshortertimeframes,improvingaccessibilityandconvenienceforpatients.ParallelImaging(PI)andCompressedSensing(CS)havebeenproposedaseffectiveapproachestoacquirehighlycompressedMRdata,resultinginreducedacquisitiontimes.WhileParallelImagingexploitsspatialinformationfrommultiplereceivercoilstoaccelerateimageacquisitionbydecreasingthenumberofphase-encodingstepsrequired,CompressedSensingMRIachieveshighaccelerationsof10timesorgreaterbyacquiringrandomsamplesink-spaceandincorporatingimagesparsityconstraintsduringreconstructionusingiterativealgorithms.However,conventionalreconstructionalgorithmsusedtoreconstructMRimagesfromundersampleddataarenotefficient,particularlyinhighlyacceleratedscenarios.Neuralnetworkshavebeenintroducedasanalternativeapproachtoaddresstheseissues.Thesemodelsexploitboththealgorithmspresentedtoachieveanimprovedcomputationalefficiency.Thecontextofthecurrentstudy,aswellastheresearchquestionsbeingaddressed,willbeintroducedbrieflyinthesecondchapter.Followingthat,thefocuswillshifttotheselectionoftheneuralnetworkusedfortheproject,aswellastheunderlyingmotivationsforthisparticularchoice.Thefourthchapterwillreviewthepreprocessingtechniquesdesignedandimplementedandthedatasetusedinthestudy.Lastly,inthefinalchapter,thetrainingprocessandstudyresultswillbethoroughlyexaminedanddiscussed.Apopularmedicalimagingmethodthatisbothhighlyefficientandwidelyusedinrecentyearsismagneticresonanceimaging(MRI).IntheUnitedStatesalone,medicalprofessionalsconductabout30millionMRIscanseachyear;thetechniqueisprimarilyusedfordetectingpathologiesanddisordersinavarietyoffields,includingoncology,neurology,orthopaedics,andmore.ThemainbenefitofMRIoverotherdiagnosticimagingtestsisitscapacitytogenerateextremelydetailedimages,allowingmedicalprofessionalstospottinyfracturesortumoursthatmightnotbevisibleonX-raysorCTscans.Tumours,jointdisease,softtissuedamage,andinternalorgandamagearejustafewoftheconditionsandinjuriesthatanMRIscancandiagnose,asMRIscanscanbeusedtolookatinternalorgansliketheliver,womb,orprostateglandaswellasthebrain,spinalcord,bones,joints,breasts,heart,andbloodvessels.MRIistypicallyusedforresearch,diagnosis,andtreatmentplanning.Thegenerationofsignals,detectionofthosesignals,andreconstructionofimagesarethreeofthestepsinvolvedintheprocessofacquiringMRIimages.Thefirststepintheprocedureinvolvespositioningthepatientwithinalargemagnetandthentransmittingradiowavesthroughhisbody,whichresultsintheprotonsabsorbingenergyandspinninginanerraticpattern.Whentheradiowavesareturnedoff,theprotonswillmovebacktowheretheywerebeforeandwillreleaseenergythatareceivercoilwilldetectandabsorb.Acomputerwillthenprocessthissignalinordertoproduceanimageoftheareaofthebodythatisbeinginvestigated.Thegenerationofasignalisaccomplishedbyfirstaligningtheprotonsinthepatient'sbodywiththemagneticfield,whichisdonewiththeassistanceofapowerfulmagneticfield.Tesla(T)unitsareusedtoexpressthemagnitudeofthismagneticfield'sstrength.Theimagequalityimprovesindirectproportiontothemagnitudeofthemagneticfield.Thedetectionofsignalsrequirestheutilizationofareceivercoil,whichmeasurestheamountofenergygivenoffbytheprotonsastheymovebacktotheirstartingposition.Thereceivercoilispositionedsothatitisencirclingtheareaofinterest,anditmonitorsforshiftsinthemagneticfieldsthatarebroughtaboutbythereturningprotons.Reconstructinganimagerequiresconvertingthesignalsthatarepickedupbythereceivercoilintoanimagethataradiologistoranotherqualifiedmedicalprofessionalcandecipher.Thisprocedureentailsseveralstages,someofwhicharereferredtoasfiltering,theInverseFouriertransformation,andimagereconstruction.K-spaceisatermusedinmagneticresonanceimaging(MRI)thatreferstothemathematicalrepresentationofthespatialfrequencydomainoftheMRIsignal.WhentheimageisdirectlyobtainedbythetechnicianoperatingtheMRscanner,theimagewillbeink-spacerepresentation,onwhichthehumanoperatorcanapplyfiltersforbetterprocessingofthedata.Specifically,k-spaceisa3DgridthatrepresentsthespatialfrequenciesoftheMRIsignal.Thex,y,andzaxesofk-spacecorrespondtothephase-encoding,frequency-encoding,andslice-selectdirectionsoftheMRIscan,respectively.Eachpointink-spacerepresentsaspecificfrequencyandphaseshiftoftheMRIsignal.Thedatacollectedink-spaceisprocessedusingamathematicalalgorithmcalledtheInverseFouriertransformtocreateanimage.TheInverseFouriertransformconvertsthefrequencydomaindataintothespatialdomain,allowingtheimagetobereconstructed.(x_i-y_i)^2wherexandyareDdimensionalvectors,andx_idenotesthevalueontheithdimensionofx.Oncewedividetheresultbythemeansquaredvalueoftheoriginalimage,wegettheNMSE.Thisnormalizationmakesthemetricscaleinvariantandallowsforafaircomparisonofmodelstrainedondifferentdatasets.Anothermetricforcomparingtwoimagesisthepeaksignal-to-noiseratio(PSNR),whichisdeterminedbydividingthemaximumsignalvaluebythetwoimages'rootmeansquareerror(MSE).ThePSNRformulais:=,clip,width="AConciseHistoryofNeuralNetworks"Inrecenttimes,thefieldofneuralnetworkresearchhasexperiencedsignificantprogress,particularlyinthe21stcentury.Thisprogresshasbeencharacterizedbyremarkableadvancementsindeeplearningtechniques,whichhaveemergedasadominantforceinthedomainsofartificialintelligence(AI)andmachinelearning(ML)applications.Theadvancementofcontemporaryhardware,particularlygraphicsprocessingunits(GPUs),hasenabledthetrainingofneuralnetworksthatareprogressivelyintricateanddeep.Asaresult,itcanbeobservedthattheseneuralnetworkshaveattainedremarkablelevelsofperformanceindiversedomainssuchasimagerecognition,languagetranslation,andgameplaying.Aneuralnetworkisacomputationalmodelthatconsistsofinterconnectedartificialneurons,whicharealsoreferredtoasnodesorunits.Thesenodesareorganizedintolayers,witheachlayerperformingaspecificfunctioninthenetwork'soverallcomputation.Theneuralnetwork'sarchitectureisdesignedtomimicthestructureandfunctionofthehumanbrain,allowingittolearnandmakepredictionsbasedoninputdata.Inthedomainofneuralnetworks,itiswidelyrecognizedthatthereexistthreefundamentalcategoriesoflayers,namelytheinputlayer,thehiddenlayer,andtheoutputlayer(Figure3.2).Theselayersareintegralcomponentsoftheneuralnetworkarchitectureandareresponsibleforprocessingandtransmittinginformationthroughoutthenetwork.Theinputlayerservesastheinitialpointofentryfordata,whilethehiddenlayer(s)processtheinformationthroughaseriesofmathematicaloperations,ultimatelyleadingtotheoutputlayer,whichproducesthefinalresultorprediction.Theseapproacheshaveproventobehighlyeffectiveinimagerecognitiontasks,asitallowsfortheefficientanalysisofcomplexvisualdata.VariousotherarchitecturalmodelshavebeendevisedtoenhancetheperformanceofFullyConvolutionalNetworks(FCNs).AmongthesemodelsareU-NetandDeepLab.ThesemodelshavebeendevelopedwiththeaimofaddressingthelimitationsofFCNsandimprovingtheirefficacyinvariousapplications.TheU-Netarchitecturehasgainedsignificantpopularityinthefieldofbiomedicalimagesegmentationduetoitsutilizationofasymmetricencoder-decoderstructure,whichisaugmentedwithskipconnections.Thisdesignchoicehasbeenshowntoenhancethelocalizationofobjectswithintheimageandfacilitatetherecoveryoffine-graineddetails.Incontrast,DeepLabisaconvolutionalneuralnetworkarchitecturethatintegratesatrousconvolutionsandspatialpyramidpoolingtechniquestoeffectivelycapturemulti-scalecontextualinformation.Thisapproachhasresultedingreatperformancesonvarioussegmentationbenchmarks..VarNetisaneuralnetworkarchitectureforvariationalinferenceinprobabilisticmodels.Thisapproachleveragesthepowerofneuralnetworkstoenableefficientandeffectivemodellingofcomplexdistributions.VarNetisapromisingdevelopmentinthefieldofmachinelearning,asithasthepotentialtosignificantlyenhancetheaccuracyandefficiencyofprobabilisticmodellingtasks.Despitenotbeingspecificallydesignedforsegmentationtasks,itpresentsitselfasanoteworthyalternativetoconventionalmodels.TheVarNetmodeliscomprisedofaseriesofnormalizingflowtransformationsthataresubsequentlyfollowedbya"base"distribution,whichistypicallyaGaussiandistribution.Normalizingflowsrepresentaclassofgenerativemodelsthatoperatebytransformingabasicprobabilitydistribution,suchasaGaussiandistribution,intoamoreintricatedistributionthroughtheapplicationofasequenceofinvertibletransformations.Thisapproachenablesthegenerationofcomplexdistributionsthatarecapableofcapturingtheunderlyingstructureofthedata.Oneoftheprimarybenefitsofemployingnormalizingflowsistheirabilitytofacilitatetheeffectivecomputationofthelog-likelihoodofthemodel.Thisisacrucialrequirementforprobabilisticinference.TheU-Netmodel,developedattheUniversityofFreiburg'sComputerScienceDepartmentforbiomedicalimagesegmentation,servesasthebaselineprovidedbyFacebookAIfortheFastMRIchallenge.Thiswell-knownconvolutionalneuralnetworkisfrequentlyusedinbiomedicalsegmentationtasksandisasafeandreliableoptionforthetask.TheU-NetarchitectureissimilartothatoftheFullyConvolutionalNetwork,withanEncoderextractingfeaturesandaDecoderbuildingthesegmentationmap.TheEncoder,whichisacontractingpart,consistsoftwo3x3convolutionsfollowedbyamax-poolingoperationwithapoolingsizeof2x2andstrideof2,whichisrepeatedfourtimeswhiledoublingthenumberoffiltersintheconvolutionallayersaftereachdown-sampling.Inmoredetail,aconvolutionallayercreatesasetofoutputfeaturemapsbyapplyinganumberoffilterstotheinputdata.Eachfilterextractsaspecificfeaturefromtheinputdata,byslidingovertheinputdataduringtheconvolutionoperation,anddeterminingateachpositionthedotproductbetweenthefilterandtheinput.Thisoperationproducesafeaturemapthatshowsthelocationsofeachfeatureintheinputdata.Ontheotherhand,themaxpoolingoperationdecreasesthedimensionalityofimagesbyloweringthenumberofpixelsintheoutputfromthepreviousconvolutionallayer.Whenusingmaxpooling,theinputimageisdividedintoanumberofnon-overlappingrectangles,andthemaximumvalueofeachrectangleisthencalculated.Theinputimage'ssizeisdecreasedthroughthisoperationwhileitsmostcrucialcomponentsarekept.Apoolinglayer'smaingoalistogatherfeaturesfrommapsproducedbytheconvolutionovertheimage.Averagepoolingandmaximumpoolingaretwopopularpoolingtechniquesthatsummarizetheaveragepresenceofafeatureandthemostactivatedpresenceofafeature,respectively.TheDecoderhasasimilarsequenceofup-samplingandtwoconvolutionoperations,withtheinputsinthefirstconvolutionstakingintoaccountboththepreviousblock'sactivationandtheactivationsfromthecorrespondingblockintheEncoder.Thissequenceisalsorepeatedfourtimes,withthenumberoffiltersdividedbytwoateachstage,followedbya1x1convolutionoperationtogeneratethefinalsegmentationmapwithoutsacrificingspatialresolution(Figure3.4).Theproposedneuralnetwork,whichaimstoincreasetheaccuracyandqualityoftheresults,isamodifiedversionoftheU-NetarchitecturebyV.Lievin.TheprimarycomponentsoftheU-Net,liketheencoder-decoderstructure,arestillpresent.Toretainmoredatafromthedatasetand,asaresult,producehigher-accuracyresults,additionalfeaturesareincludedinthisarchitecture.Oneofthekeyfeaturesoftheproposednetworkistheuseof'DilatedConvolution'blocks.Incontrasttoconventionalconvolutions,theseconvolutionsalsoincludeadilationfactorthatcontrolsthespacingbetweenthekernelpoints.Dilatedconvolutionoperationsexpandthefilterbyintroducinggapsbetweenthefiltervalues;thesizeofthegapsisdeterminedbythedilationrate,whichisahyperparameter(whichcanbechangedarbitrarily).Bysettingthedilationrateto1,wewouldperformaregularconvolution.Becausethefilterisstillthesamesizebuthasgapsbetweenthevalues,thedilationrateeffectivelyexpandsthereceptivefieldofthefilterwithoutincreasingthenumberofparameters.Thiscanbeusefulinsituationswherealargerreceptivefieldisneeded,butincreasingthesizeofthefilterwouldleadtoanincreaseinthenumberofparametersandcomputationalcomplexity.Dilatedconvolutionsareabletocaptureawidercontextthanstandardconvolutionsbecausethespacingbetweenthekernelpointsisincreased.TheyareusedintheRes-U-Netarchitecturetoaccuratelysegmentmedicalimagesbycapturingbothlocalandglobalfeaturesoftheinputimage.TheyrequiretwotensorsproducedbytheConvolutionalEncoderasinputandaremadeupoftheBatchNorm,ReLu,andDropoutfunctions.Atensorwiththedimensions64x256x3x3istheoutputoftheDilatedConvolutionblockandissenttotheConvolutionalDecoder.Dilatedconvolutionshavebeenusedsuccessfullyinvariousapplicationssuchassemanticsegmentationwherealargercontextisneededtoclassifyeachpixelandaudioprocessingwherethenetworkneedstolearnpatternswithlongertimedependencies.TheResidualBlockisyetanothercrucialcomponentoftheproposednetwork,introducedaspartoftheResNetarchitecture.Astackoflayerscalledaresidualblockissetupsothateachlayer’soutputisaddedtoalayerfurtherdownthestack.Theyare,inotherwords,particularskipconnectionblocksthatlearnresidualfunctionswithreferencetothelayerinputsinsteadoflearningunreferencedfunctions.Moreformally,weletthestackednonlinearlayersfitanothermappingofF(x)=70mm,scale=100mmThisstudyisbasedontheofficialFastMRIdatasetprovidedbytheradiologydepartmentatNYU.ThesaiddatasetincludesMRIscansofthekneeandbrainthatwereperformedusingsingle-coilandmulti-coilmethods,respectively.However,ourresearchisprimarilyfocusedonmulti-coilbrainimages.Thedatasetconsistsof6,970fullysampledbrainMRIsthathavebeende-identifiedinaccordancewithHIPAAregulationsbyNYULangoneHealth,capturedon3and1.5Teslamagnets.Theimagesaredividedinto3,001at1.5Tand3,969at3T.AxialT1,AxialT1weighted,T2weighted,FLAIRandT1weightedwithcontrastagent(T1POST)arethesequencesthatcanbefoundintherawdataset.Eachoneofthemisusedtohighlightcertainaspectsofthepicture:T2weightedsequencesareprimarilyusedtoidentifypathologicalchangesinneuraltissue,whereasT1weightedsequencesarehelpfulforexaminingthenormalanatomyofthebrain.WhileT1weightedisreferredtoastheT1timemeasuredintheabsenceofacontrastagent,post-contrastT1istimemeasuredaftertheapplicationofgadoliniumisusedtocalculateextracellularvolume(ECV),asurrogateparameterfortheextracellularmatrix.FLAIRisaparticularinversionrecoverysequencethatremovescerebrospinalfluidsignalfromtheresultingimagesbuthasalonginversiontime.GreymatterisbrighterthanwhitematterinbraintissueonFLAIRimages,whicharesimilartoT2weightedimages,butcerebrospinalfluidisdarkratherthanbright.It'sworthmentioningthatsomeT1-weightedacquisitionsincludecontrastmaterials.Eachfilecontainsaround30slicesoffullysampledimagesfromtheMRIsamplesandisstoredintheHierarchicalDataFormat(HDF).Thedatasetconsistsoffivedistinctcomponents:training,validation,multi-coiltest,multi-coilchallenge,andsingle-coilchallenge,whichwererandomlyallocatedbytheNYUHealthdepartment.ThissystematicorganizationallowsfortheevaluationandcomparisonofvariousMRIreconstructionalgorithms,contributingtotheoverarchinggoaloftheFastMRIproject.FieldStrength&1.5T&3T&Total\\T1&375&407&782\\T1POST&849&641&1490\\T2&1651&2515&4166\\FLAIR&126&406&532\\)),whereD()representstheacquiredk-spacedata,C()representsthecoilsensitivitymapink-space,andistheconvolutionoperation.GRAPPAcanestimatethemissingk-spacedata,S_m(),usingalinearcombinationofneighboringacquireddatapoints:S_m()=1^w_iD(-_i),wherew_irepresentstheGRAPPAweights,Nrepresentsthenumberofneighboringpoints,and_irepresentsthek-spacecoordinatesoftheneighboringpoints.:l-=get_low_frequency_lines(mask)num_low_freqs=(mask.shape-num_low_freqs+1)//2calib=grappa(tensor_to_complex_np(masked_kspace),tensor_to_complex_np(calib),kernel_size=0)returnto_tensor(preprocessed_masked_kspace)PriortotheintroductionoftheESPIRiT,SENSEandGRAPPAwerethemostfrequentlyusedparallelMRIreconstructiontechniques.SENSEisacoil-by-coilreconstructionmethodthatusesfullysampledreferencedatatoestimatethecoilsensitivities,whicharethenusedtounfoldthealiasedimages.SeparatecoilsensitivitymapsarenecessaryforSENSE,thoughtheycanbetime-consumingtoacquireandriskincludingerrorsifnotestimatedcorrectly.GRAPPA,ontheotherhand,isadata-drivenapproachthatusesthevariationsincoilsensitivitytoinferthemissingk-spacedatafromnearbyacquireddatapoints.GRAPPAreliesontheregularityofthesampledk-spacedataratherthanexplicitknowledgeofthecoilsensitivities.Whenusedalone,GRAPPAmayexperiencenoiseamplificationandlimitedaccuracyinhighlyundersampleddata.BycombiningtheadvantagesofSENSEandGRAPPA,ESPIRiTisanovelstrategythatfillsthegapbetweenthem.ThecentralconceptofESPIRiTistosimultaneouslyestimatethecoilsensitivitymapsandthemissingk-spacedatausinganeigenvaluedecompositionmethod.ThisisaccomplishedbyrewritingtheparallelMRIproblemasaneigenvectorproblem,wherethecoilsensitivitiesarerepresentedbytheeigenvectorswiththelargesteigenvaluesandthemissingk-spacedataisencodedbytheeigenvectorswiththesmallesteigenvalues.ThefoundationofESPIRiTistheideaofsubspace-basedmethods,whichhavebeenextensivelyappliedtoimageandsignalprocessing.ThecalibrationmatrixfortheESPIRiTmethodisbuiltfromtheacquiredk-spacedata,whichcapturestheinherentcorrelationsbetweenvariouscoilchannelsandthespatialorganizationofthecoilsensitivities.C=UV^HwhereUandVareunitarymatrices,andisadiagonalmatrixcontainingtheeigenvaluesofC.Thecoilsensitivitymapsarecreatedusingtheeigenvectorslinkedtothelargesteigenvalues,andtheyarethenusedtounfoldthealiasedimagessimilarlytoSENSE.S_=^HS_^HwhereS_^Histheconjugatetransposeoftheestimatedsensitivitymaps.Theunfoldedimagesandtheestimatedmissingk-spacedataarethencombinedwithaninverseFourierTransformtocreatethereconstructedimages.x=OriginalPaperESPIRiThasanumberofbenefitsoverconventionalparallelMRItechniques.ThefirstbenefitisthatitoffersauniformframeworkforparallelMRIreconstructionthatcombinestheadvantagesofbothGRAPPAandSENSE.Second,itsimplifiesthereconstructionprocessandlowerscomputationalcomplexitybynotrequiringseparateestimationofthecoilsensitivitymapsandthemissingk-spacedata.Thirdly,becausetheeigenvaluedecompositionmethodislesssensitivetonoiseanderrorsintheacquireddata,itisinherentlyrobusttonoiseandartefacts.AnotherillustrationofthevariationsbetweenundersampledMRIdatareconstructionusingvariousalgorithmsisshowninFigure4.7.TheresidualsignalisreducedtoitsminimumbyusingtheNLINValgorithmandESPIRiTdirectlyontheslice,butitisnotcompletelyreducedbySENSE.NLINVisanotherreconstructionalgorithmusedtoproducehigh-qualityimagesfromMRIdatathatishighlyundersampled.Itisanon-linearinversereconstructionmethodthatinvolvesiterativelysolvinganon-linearproblemtoestimatetheunderlyingimagefromtheacquiredk-spacedata,usingtheideaofregularizednon-linearinversion.RegardingthespecificimplementationofESPIRiT(Code4.2),thefunctiontakesinthek-spacedataandreconstructedimageasinputandreturnsthecombinedimage.ItfirstperformsafewtransformationsoftheimageaxesandthencreatesandrunstheSigPyimplementationoftheESPIRiTcalibrationfunctionwiththek-spacedataastheonlyinput.ThisprocessmaytakeafewsecondsandwillreturnESPIRiTcoilsensitivitymapsofthesamesizeasthek-spacedata.Thefunctionthencombinesthecoilsensitivitymapswiththeimagedatausingelement-wisemultiplicationandsummationalongthecoildimension.Theideabehindcoilcombinationistoweighteachcoilimagebyitscorrespondingsensitivitymapsothattheresultingcombinedimagehasahighersignal-to-noiseratio(SNR)andreducedartefacts.defstandardize_multi_coil_image(kspace,image):#Permutek-spacedatasothatthecoildimensionisthelastkspace_perm=np.expand_dims(kspace_perm,axis=mri.app.EspiritCalib(kspace)#ComputetheESPIRiToperatorusingthecalibrationobjectS=np.sum(np.multiply(np.conj(S),image),axis=np.expand_dims(M_comb,axis=to_tensor(kspace)#applymaskmasked_kspace,mask=seed)#applyGrappamasked_kspace=fastmri.ifft2c(masked_kspace)#applyESPIRiTimage=to_tensor(image)#ReturnsthetuplewithprocesseddatareturnUnetSample(image=target_torch,mean=std,fname=slice_num,max_value=102mmThevalidationlossgraph(Figure5.4)providesamorecomprehensiveillustrationofthelearningevolutionthroughoutthe50epochs.Themodel'sperformanceimprovesrapidlyinthefirstfewepochs,attributabletothehighlearningrate,butthengraduallystagnatesandcannotachievelowervaluesforaprolongedperiod.Aroundtheendofthetraining,theoptimalvalidationlossvalueof0.10537isthebestobtained.Inthe8xtrack,theresultswereconsistentlyworsethanintheprevioustrack,duetothedatabeingdeeplyundersampled,withonlyaround60\Oneimportantmodificationwastheimplementationofanalgorithmcalled'',developedbytheLightningTeam.Thisalgorithmtestsdifferentlearningratesandselectsthemostappropriateoneafterafewstepsoftraining;inourcase,thelearningratethatwaspreferredwas10^.Thisapproachwaschosenaftercarefulconsiderationoftheprevioustraininginthe4xtrack,ashigh-weightupdatescouldbeproblematicwithsuchundersampleddata.Inadditiontothe''algorithm,weightdecayanddropoutprobabilitywereintroducedinthistracktofurtherimprovethemodel'sperformance.Weightdecayisaregularizationtechniquethataimstopreventoverfittingbyaddingapenaltytermtothelossfunctionthatencouragesthemodeltohavesmallerweightvalues.Thisisbecauselargerweightscanleadtooverfittingastheymaycausethemodeltobecometoospecializedtothetrainingdataandnotgeneralizewelltonewdata.Overfittingisacommonphenomenoninmachinelearningthatwetrytoavoidwhichoccurswhenamodelisexcessivelytrainedonaparticulardataset,leadingtothemodellearningtheidiosyncraticfeaturesornoiseinthedatainsteadoftheunderlyingpatterns.Consequently,suchamodelmayperformexceptionallywellonthetrainingdatabutmaynotgeneralizewelltonew,unseendata.Dropoutisanothertechniqueusedtopreventoverfittingbyrandomlydroppingoutsomeoftheneuronsduringtraining.Thismeansthatsomeoftheneuronsinthemodelwillbeignoredduringeachtrainingiteration,whichforcesthemodeltolearnmorerobustandgeneralizablefeatures.Dropoutcanbethoughtofasawaytopreventthemodelfromrelyingtooheavilyonanyonefeatureorcombinationoffeatures,whichcanleadtooverfitting.Thesemodificationswereaimedatimprovingthemodel'sabilitytohandlethechallengesposedbythedeeplyundersampleddataandultimatelyproducehigher-qualityresults.Isetbothofthesevaluestoastandardvalue,specificallydropoutprobabilitywassetto0.5andweightdecayto10^.Moreover,Ioptedfor70epochsinthisrun,formanyreasons.First,increasingtheaccelerationfactorfrom4xto8xrequiredmoretrainingtimetocapturethefinerdetails,andalsothedatahasmorecomplexfeaturesandpatternsthatthearchitectureneedstodecryptandthatrequireadditionaltrainingtimetolearn.Finally,usingalargernumberofepochshelpedthemodeltograduallyrefineitsunderstandingofthedataovertimewithalowerlearningratethanbefore.Inpictures5.13,5.14and5.15,isshownarandomsliceofMRdatathathasbeenprocessedwithan8xacceleratedmask.Thevalidationlossgraph(Figure5.17)providesacrucialoverviewofthemodel'slearningprogressduringthe70epochs.Withalowerlearningrate,themodel'sperformancesteadilyimprovesintherightdirectionthroughoutthetrainingprocess.Bythe40thepoch,astablevalueisreached,indicatingthatthemodelhasreacheditsoptimalperformance.Then,itslightlyimprovesitsSSIMvalueoverthefinalepochs,reachingaminimumof0.12511atthe65thepoch.Inthissection,IwilldiscusstheresultsofmyworkonacceleratedMRIreconstruction.Iaddressedthisproblembydevelopinganeuralnetwork-basedapproachandincorporatingtwopowerfulpreprocessingmethods.Toevaluatetheeffectivenessofmyapproach,Iconductedexperimentsattwodifferentaccelerationfactors,4xand8x.Forthe4xaccelerationfactor,myneuralnetworkwasabletoconvergetoaminimumlossresulteffectively.Iemployedalearningrateof10^forthefirst40epochs,followedbyadecreaseto10^tofacilitateconvergencetoabetterminimum.Iobservedthatthelowestlossfunctionvaluewas0.03225,andthecorrespondingSSIMreachedanimpressivevalueof0.96775onthetrainingsplit,whiletheaveragevalidationsetscorereached0.9284.Afterexaminingthebestreconstructionofimagefile15800inthe4xtrack,wezoomedinonapproximatelythesameregionwithdifferentlevelsofmagnification(Figure5.26).Whileweobservedthatafewdetailsweremissing,overalltheimagequalitywasgreat.Similarly,infile9605,asshowninFigure5.27,theimagequalityisgenerallyappreciable;however,therearesomeregionsthatappearblurred.WhenexaminingFigure5.28,itbecomesapparentthatthereisanimprecisioninthereconstruction.Specifically,thebrainimageisnotdemarcatedcorrectly,makingiteasytospotfewerrors.Thevalidationlossgraphprovidedacomprehensiveillustrationofthelearningevolutionthroughoutthe50epochs.Themodel'sperformanceimprovedrapidlyinthefirstfewepochs,thankstothehighlearningrate.Towardtheendofthetraining,theoptimalvalidationlossvalueof0.10537wasthebestobtained.Thebestresultsforeachmetricwereachievedduringthefinalepochsofthetraining,includingaPSNRof37.5703atthe43rdepochandNMSEandSSIMvaluesof0.01446and0.9284,respectively,atthe46thepoch.Theseresultsdemonstratetheeffectivenessofourmodelforthe4xaccelerationfactor.Forthe8xaccelerationfactortrack,wefacedamorechallengingscenarioduetothedeeperundersamplingofthedata,withonlyaround60\Weincreasedthenumberoftrainingepochsto70forthe8xtrack,whichallowedthemodeltocapturefinerdetailsandcomplexpatternsinthedata.Thebestlossfunctionvalueachievedduringtrainingwas0.04693,andthevalidationlossgraphshowedasteadyimprovementinperformancethroughoutthetrainingprocess.Themodelreachedastablevaluebythe40thepochandachievedaminimumvalidationlossof0.12511atthe65thepoch.Themetricsfurtherconfirmedtheeffectivenessofourapproachforthe8xaccelerationfactor,withamaximumSSIMof0.8984achievedbytheendofthetrainingprocess.Althoughthisvalueislowerthanthatobtainedforthe4xtrack,itisstillaremarkableresultgiventhechallengeofreconstructingimagesfromonlyasmallpartoftheavailabledata.Byexaminingtwospecificfilesandzoomingin2xand3xonaslice(Figures5.29to5.31),wecancomparetheimagestothegroundtruthandanalyzethem.Wecanobservethatmultipleregionsoftheimagearetooblurredtobeuseful.Inthis8xtrack,thedatawasdeeplyundersampled,leadingtoareconstructionthathaslimitedpracticalvalueforspecialists.Whiletheresultisexceptionalconsideringhowundersampledthedatawas,thesefigureswouldnotbeusefultoradiologistsastheylackdetailsandexhibitblurrybrainstructures.Inthenexttable,asummaryoftheteams'resultsalongwithourarchitecture,forboth4xand8xtracks.Team&4xTrack&8xTrack&Average\\AIRSMedical&0.964&0.952&0.958\\ATB&0.960&0.944&0.952\\Neurospin&0.959&0.942&0.9505\\&&&\\ThistableshowsasummaryofSSIM(StructuralSimilarityIndex)resultsforeachteamintheFastMRI2020competition.Thetableindicatesthattheproposedarchitecture,representedbythe"Ours"team,obtainedslightlylowerSSIMvaluescomparedtothetopthreeteams(AIRSMedical,ATB,andNeurospin)inboththe4xand8xtracks,withthe"Average"columndisplayingtheaverageSSIMscoreacrossbothtracks.The"Ours"teamhadthelowestaverageSSIMscorecomparedtotheotherteamsintheFastMRI2020competition.Togetabetterideaofhowtheperformanceofmyarchitecturecomparedtotheotherteams,IcalculatedthepercentualdifferencebetweentheSSIMscoreofthe"ours"teamandtheSSIMscoresofeachoftheotherteams.ThepercentualdifferencebetweenourresearchandtheteamwiththehighestSSIMscore,AIRSMedical,was3.07\Moreover,theresultsfromthespecificsequencesaresimilartoours,asallteamsincludingourshadthelowestresultsintheFLAIRsequence,indicatingthatitwasthemostchallengingtoreconstruct.Feedbackwasreceivedfrombothparticipatingandnon-participatingteams,withthesecondstatingthattheywereunabletoparticipateduetothehighcomputationalandstoragerequirements.Inthefuture,researcherssuggestedthatitwouldbebeneficialtolowerthebarrierstoentry,especiallyforacademicgroupsthatmayhaveinnovativemethodsbutlimitedcomputingorstorageresources.AnotherfeedbackreceivedwasregardingtheuseofSSIMastheprimarymetricforevaluatingtheimages,whichtendstopromotesmoothing,ratherthanrelyingonradiologistinterpretation.Bothoftheseissuesareoffundamentalimportanceandrequirefurtherinvestigation.Inconclusion,ourworkdemonstratesthepotentialofdeeplearningtechniquesforacceleratedMRIreconstruction.Ourneuralnetwork-basedapproachwasabletoeffectivelyreconstructhigh-qualityimagesfromundersampledk-spacedata,buttheresultsathighaccelerationfactors(8x)werelessoperablebyspecialistsduetotheirblurryandnotdetailedquality.Aftercomparingmyimagesandscorestothoseofotherteams,itbecameapparentthattheissuesobservedwerecommontotheiralgorithmsaswell.Thisobservationsuggeststhattheproblemmaybeinherenttothetaskitself,ratherthanspecifictomyapproach.Theresultsobtainedforboththe4xand8xaccelerationfactorsshowcasetheeffectivenessofourmethodanditsabilitytohandlethechallengesposedbyundersampleddata.Inconclusion,thisthesishaspresentednovelneuralnetworkarchitecturesdesignedtoaddressthechallengesassociatedwithreconstructinghighlyacceleratedMRIdata.WehavedevelopedaResidual-U-Netcapableofhandlingcomplexdatainconjunctionwithstate-of-the-artpreprocessingmethods,namelyESPIRiT(eigenvalueapproachtoautocalibratingparallelMRI)andGRAPPA(Generalizedautocalibratingpartiallyparallelacquisitions).ThesuccessfulimplementationofthesearchitecturesdemonstratesthepotentialofneuralnetworkstoenhancethecomputationalefficiencyofMRimagereconstruction.Toassesstheeffectivenessofourapproach,wetrainedtheproposedarchitectureontheNYUMRIdatasetusingtwodistincttraininginstanceswithtwoundersamplingtechniques,reducingtheamountofdataacquiredbyfactorsof4(4x)and8(8x),respectively.TheresultingreconstructionswerecomparedtothoseachievedbyteamsparticipatingintheFastMRIchallenge,utilizingwell-establishedmetricssuchasSSIM,PSNR,andNMSE.Ourfindingsindicatethatourproposedmethodologymatchestheperformanceofstate-of-the-artmethodsemployedbyotherteamsintheFastMRIchallenge.Thiscontributionaddstothegrowingbodyofknowledgesurroundingdeeplearningapplicationsinmedicalimaging,withpotentialimplicationsforthedevelopmentofadvancedtechniquesinacceleratedMRIreconstruction.Whenradiologistsprovidedfeedbackonthereconstructedimages,theyreportedthatforthe4xtrack,therewereoftennosignificantdifferencesbetweenthereconstructionsandthegroundtruth,andtheycouldworkwiththeseimageswithoutanyissues.Thissuggeststhatourresultswouldlikelybewell-receivedbymedicalprofessionalsinthecontextofthe4xtrack.However,theresultsfromthe8xaccelerationfactorinstancestudysuggestthatfurtheroptimizationandenhancementsareneededtoproducehigher-qualityreconstructionsforimagesobtainedfromdeeplyundersampleddata.Theloweraccuracyresults,blurredreconstructions,andhallucinationfeaturesobservedintheimagesindicatethattheseaspectsrequireadditionalinvestigationanddevelopment,astheyhavenotbeenthoroughlyaddressedbyourworkorthatofotherteams.Inlightoftheseconsiderations,thealgorithmsstudiedhavesucceededinsignificantlyincreasingtheeffectivenessofMRIscansbycuttingscantimesbyuptofourtimeswhilemaintaininghighimagequality.ThesealgorithmsmayincreasetheavailabilityandaffordabilityofMRIscans,whichcouldsignificantlyaffecthealthcare.Futureresearchshouldexplorealternativetrainingparametersortechniquestofurtherimprovemodelperformance.Potentialavenuesincludedifferentregularizationtechniques,alteringthelossfunction,extendingtrainingepochs,investigatingnewarchitectures,andensuringtheabsenceofimageartefactsorfalsefeatures(i.e.,hallucinations).Insummary,thefindingsofthisstudycontributetothefieldofMRimagereconstructionandholdpromiseforadvancementsinmedicalimagingtechniques.Desideroringraziaretutticolorochehannocontribuitoalcompletamentodelmiopercorsoaccademico,siacolorochemihannoaccompagnatodasempre,siaquellichesonoarrivatipiùrecentementenellamiavita.Unringraziamentospecialeaimieiamicidisempre,GabrieAli,chemisopportanoemisupportanodallontano2012.Sietestatilacostantenellamiavitaenonpotreichiedereamicimigliori.VoglioringraziareanchetuttalaPaulaGvng,compostadaAngelica,Giorgia,Roberta,Bea,Martina,nonchéleestensionidelcerchio,Chiara,AriannaeSocci.Ungraziedicuoreall'unicocollegadicuihomaiavutobisogno,Adriano,chehacommentatolamiatesiesclamando:"Maèunnuovococktail?".Unringraziamentospecialeancheainuoviarrivati,fintiatletimaveriamici:Michele,Riccardo,Flavia,etuttiglialtri.Sietestatiunapresenzapreziosadurantetuttoilmiopercorso.Grazieperavermifattoridereeperavermiassecondatonellemieidiozieadatleticacondividendoconmetanteesperienzeindimenticabili.DesideroesprimerelamiaprofondagratitudineversoRusso+Assogna,chesonostatipermecomeunafamigliaromanadurantetuttoilmiopercorso.RingraziodicuoreGiulia,Marghe,LucaPiccolo,LucaGrande,PaolaeGianlucaperavermiaccoltoabracciaaperteeperavermifornitounambientecosìcaloroso.Desideroringraziareinmodoparticolarelaragazzacheèsemprestataalmiofianco,echehasvoltounruolofondamentalenelraggiungimentodiquestotraguardo.Gippa,questalaureamagistraleèanchetua,perchétuhaisempresaputoincoraggiarmi,ascoltarmiesostenermi,ancheneimomentidifficili.Nonriescoaringraziartiabbastanzaperessertisemprepresacuradime,sianeimomentifelicicheinquellidifficili.Graziepernonessertimaistancatadime,anchedoposettimaneinsieme24oresu24.Sesonoquioggi,lodevoinparteate,eperquestotisaròsempregrato.Infine,voglioringraziarelamiafamiglia,cheèsemprestatapresenteenonsièmaiallontanata:Mamma,Papà,Laura,Simone,DavideeBeba.Graziealvostroesempio,hotrovatolaforzadiperseverareneglistudi,nonostanteavessisemprepensatodinonessereall'altezza.Ora,guardandoindietro,sonofelicedidirechecel'hofatta,esonogratoperl'ispirazionechemiavetedato.