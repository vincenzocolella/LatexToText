 labellst1 floatfigure pdfauthor pdfkeywords This thesis proposes novel architectures to address the challenges associated with the reconstruction of undersampled MRI data using neural networks The proposed approach involves designing and implementing a neural network the Residual UNet along with two stateoftheart preprocessing methods Compressed Sensing and Parallel Imaging architectures included to further improve the results obtained Specifically the GRAPPA Generalized Autocalibrating Partially Parallel Acquisitions and ESPIRiT Eigenvectorbased SPIRiT algorithms will be applied to the MRI data to enhance the performance of the new architecture The effectiveness of the proposed approach will be evaluated by training the new architecture on the NYU Health dataset in two distinct training instances using two undersampling techniques where the amount of data acquired is reduced by a factor of 4 4x and 8 8x respectively The results obtained will be compared with those achieved by the teams that participated in the FastMRI challenge using wellknown metrics such as SSIM PSNR and NMSE The purpose of this thesis is to investigate and analyze the potential of neural networks in enhancing the computational efficiency of MR imaging The primary objective is to explore how neural networks can be leveraged to accelerate the entire scan process by a factor of four thereby significantly reducing the total duration of the scan The thesis contributes to the field of MRI reconstruction by providing insights into the effectiveness of the ResUNet and two specific preprocessing methods GRAPPA and ESPIRiT to improve the duration of Magnetic Resonance Imaging agnetic Resonance Imaging MRI is a commonly used imaging technique that is noninvasive and does not use ionizing radiation making it safe for imaging soft tissues However the lengthy scan time required for MRI can limit its application particularly for patients who cannot remain still for extended periods or require urgent results To address these challenges researchers are developing faster MRI techniques that can produce highquality images in shorter time frames improving accessibility and convenience for patients Parallel Imaging PI and Compressed Sensing CS have been proposed as effective approaches to acquire highly compressed MR data resulting in reduced acquisition times While Parallel Imaging exploits spatial information from multiple receiver coils to accelerate image acquisition by decreasing the number of phaseencoding steps required Compressed Sensing MRI achieves high accelerations of 10 times or greater by acquiring random samples in kspace and incorporating image sparsity constraints during reconstruction using iterative algorithms However conventional reconstruction algorithms used to reconstruct MR images from undersampled data are not efficient particularly in highly accelerated scenarios Neural networks have been introduced as an alternative approach to address these issues These models exploit both the algorithms presented to achieve an improved computational efficiency The context of the current study as well as the research questions being addressed will be introduced briefly in the second chapter Following that the focus will shift to the selection of the neural network used for the project as well as the underlying motivations for this particular choice The fourth chapter will review the preprocessing techniques designed and implemented and the dataset used in the study Lastly in the final chapter the training process and study results will be thoroughly examined and discussed A popular medical imaging method that is both highly efficient and widely used in recent years is magnetic resonance imaging MRI In the United States alone medical professionals conduct about 30 million MRI scans each year the technique is primarily used for detecting pathologies and disorders in a variety of fields including oncology neurology orthopaedics and more The main benefit of MRI over other diagnostic imaging tests is its capacity to generate extremely detailed images allowing medical professionals to spot tiny fractures or tumours that might not be visible on Xrays or CT scans Tumours joint disease soft tissue damage and internal organ damage are just a few of the conditions and injuries that an MRI scan can diagnose as MRI scans can be used to look at internal organs like the liver womb or prostate gland as well as the brain spinal cord bones joints breasts heart and blood vessels MRI is typically used for research diagnosis and treatment planning The generation of signals detection of those signals and reconstruction of images are three of the steps involved in the process of acquiring MRI images The first step in the procedure involves positioning the patient within a large magnet and then transmitting radio waves through his body which results in the protons absorbing energy and spinning in an erratic pattern When the radio waves are turned off the protons will move back to where they were before and will release energy that a receiver coil will detect and absorb A computer will then process this signal in order to produce an image of the area of the body that is being investigated The generation of a signal is accomplished by first aligning the protons in the patients body with the magnetic field which is done with the assistance of a powerful magnetic field Tesla T units are used to express the magnitude of this magnetic fields strength The image quality improves in direct proportion to the magnitude of the magnetic field The detection of signals requires the utilization of a receiver coil which measures the amount of energy given off by the protons as they move back to their starting position The receiver coil is positioned so that it is encircling the area of interest and it monitors for shifts in the magnetic fields that are brought about by the returning protons Reconstructing an image requires converting the signals that are picked up by the receiver coil into an image that a radiologist or another qualified medical professional can decipher This procedure entails several stages some of which are referred to as filtering the Inverse Fourier transformation and image reconstruction Kspace is a term used in magnetic resonance imaging MRI that refers to the mathematical representation of the spatial frequency domain of the MRI signal When the image is directly obtained by the technician operating the MR scanner the image will be in kspace representation on which the human operator can apply filters for better processing of the data Specifically kspace is a 3D grid that represents the spatial frequencies of the MRI signal The x y and z axes of kspace correspond to the phaseencoding frequencyencoding and sliceselect directions of the MRI scan respectively Each point in kspace represents a specific frequency and phase shift of the MRI signal The data collected in kspace is processed using a mathematical algorithm called the Inverse Fourier transform to create an image The Inverse Fourier transform converts the frequency domain data into the spatial domain allowing the image to be reconstructed Coyne 2012 MRI scans do have some disadvantages many of which are related to their extended duration For some patient groups like pregnant women who must proceed with caution during an MRI this can be a significant challenge Even though MRI scans are thought to be safe during pregnancy caution should still be exercised especially during the first trimester as contrast enhancements based on gadolinium which are frequently used to enhance the clarity of MRI images can pass through the placental tissue and be ingested by the fetus having longterm effects Studies have shown a marked increase in inflammatory rheumatologic and infiltrative skin conditions in pregnancies exposed to gadoliniumbased MRI with respect to the pregnancies which were not exposed to any MRI exam 123 versus 384180 births resulting in an adjusted risk difference of 453 per 1000 person years Also stillbirths and neonatal deaths were noticed as more frequent in the case of gadolinium MRI exposure The effects on patients who have cochlear implants are a further worry regarding the use of MRI scans Despite the fact that 3T radiation has been used to demonstrate the safety of modern implants some patients have reported complications like magnet rotation by 90 degrees which led to a slight loss of magnetism Patients who have had cochlear implantation because of hearing loss and need routine MRI scans for unrelated conditions may find this to be of particular concern Children and elderly people may have trouble staying still for long periods during an MRI scan which can cause discomfort and distress In particular young children and babies may need a general anaesthetic to keep them still while elderly individuals may experience particular challenges due to agerelated conditions such as mobility limitations cognitive impairment and the presence of medical devices These factors can impact the quality of MRI images and increase the risk of patient discomfort or injury As a result scientists and medical experts have been looking into alternate methods to improve imaging quality while shortening scan times Compressed sensing is one such method that makes use of sophisticated algorithms to reconstruct an image from a condensed set of measurements allowing for faster scan times and reduced radiation exposure for patients When scanning dynamic structures like the heart where multiple images must be taken quickly after one another this technique is especially helpful Parallel imaging is another method that has gained popularity recently It uses multiple coils to simultaneously acquire various signal components which can create a higherquality image more quickly by combining the data from these coils This technique is particularly useful for imaging large regions of the body such as the brain or spinal cord where high spatial resolution is required Parallel imaging is also useful for reducing scan times and minimizing patient discomfort While speeding up the scan could address these issues the quality of the final image might be affected A poorquality image may unnecessarily obstruct the diagnosis process or even result in erroneous or imprecise diagnoses This can be particularly problematic when determining the diagnosis of complicated and serious medical conditions like cancer In conclusion MRI scans like any diagnostic tool have certain limitations that must be considered Due to these drawbacks which include the prolonged scan time and the potential for complications in some patient populations alternate techniques like compressed sensing and parallel imaging have been developed By combining these tools with cuttingedge technologies like machine learning we may be able to shorten scan times without sacrificing image quality which would help with complex medical condition diagnosis and treatment The fastMRI challenge is a public dataset and competition that aims to improve the efficiency of magnetic resonance imaging MRI scans by using machine learning techniques It was launched in 2018 by Facebook AI Research and the New York University NYU School of Medicine The fastMRI dataset contains raw kspace data and corresponding images from over 8564 knee and brain MRI scans The goal of the challenge is to develop algorithms that can accurately reconstruct highquality images from undersampled kspace data meaning achieve the goal to improve the speed of MRI scans by letting them acquire less data and then accurately reconstruct the resulting undersampled kspace image through algorithms The FastMRI challenge 2020 involved two tracks the singlecoil track and the multicoil track The former involved reconstructing highquality images from undersampled kspace data using only one coil while the latter utilized multiple coils to achieve the same goal The multicoil track was considered more challenging due to the increased complexity of the data and the need to account for variations in coil sensitivity The challenge provides a training dataset a test dataset and a validation dataset both of which contain raw kspace data and corresponding images The peak signaltonoise ratio PSNR and structural similarity index SSIM between the reconstructed images and the ground truth images are the primary metrics used in the challenge to assess the algorithms along with the wellknown Normalized Mean Squared Error NMSE Specifically the NMSE Normalized Mean Squared Error is calculated as the ratio of the mean squared error MSE between the two images to the mean squared value of the original image and is a metric for comparing the differences between two images The MSE formula is xiyi2 where x and y are D dimensional vectors and xi denotes the value on the ith dimension of x Once we divide the result by the mean squared value of the original image we get the NMSE This normalization makes the metric scale invariant and allows for a fair comparison of models trained on different datasets Another metric for comparing two images is the peak signaltonoise ratio PSNR which is determined by dividing the maximum signal value by the two images root mean square error MSE The PSNR formula is 20 where MSE stands for mean square error is the base10 logarithm and maxI is the highest possible pixel value The structural similarity between two images is measured by the SSIM Structural Similarity Index metric Its formula is where is their covariance and c1 and c2 are small constants to prevent division by zero SSIM is a perceptionbased measure that considers image degradation as a perceived change in structural information while also incorporating important perceptual phenomena including both luminance masking and contrast masking terms Unlike other techniques like MSE or PSNR that estimate absolute errors SSIM takes into account structural information This means that SSIM considers the strong interdependencies between pixels especially when they are spatially close which carry important information about the structure of objects in the visual scene In addition SSIM considers the phenomenon of luminance masking which refers to image distortions being less visible in bright regions and contrast masking which refers to distortions becoming less visible where there is significant activity or texture in the image For the reasons stated above MSE and NMSE being errors must be minimised while SSIM and PSNR need to be maximized since the former represents image similarity while the latter shows relative image quality Machine learning algorithms have the potential to increase the effectiveness of MRI scans as the fastMRI challenge has shown The successful algorithms that emerged as winners against over 1500 participants that often didnt submit their work but posted it online have demonstrated the feasibility of reconstructing highquality images from undersampled kspace data and consequently achieving an increase in the accessibility and costeffectiveness of MRI scans For scientists and programmers working to advance medical imaging the fastMRI dataset and challenge continue to be invaluable resources The stateoftheart works in MRI reconstruction come from the 2020 FastMRI challenge where Facebook evaluated 19 submissions from 8 different groups For simplicity we will only analyze the results for brain multicoil images which are more challenging and interesting to study The best four teams AIRS Medical ATB MRRecon MRR and Neurospin Nspin were chosen for the finals based on their performance The projects had varying characteristics with the number of model parameters ranging from 841000 in the case of ResoNNance to 200 million in the case of AIRS Teams used either GRAPPA or simple zerofilled initializations for coil estimation with some employing ESPIRiT or centrebased estimation with UNet refinement similar to that in the EndtoEnd Variational Network The challenge included two tracks the 4x track focused on reconstructing brain MRI images from only 25 In contrast the FLAIR sequence had the lowest SSIM values for all three teams with AIRS Medical achieving the highest value of 0930 followed by ATB with 0924 and Neurospin with 0920 This indicates that FLAIR reconstruction is more challenging than the other sequences and further research is needed to improve the reconstruction quality The topperforming algorithm an AIRSnet utilized a deep neural network architecture based on the UNet model It consisted of a cascade of 4 UNets where the channels in each convolutional layer were split to work in both kspace and image space domains functionally The model was initialized through multiple GRAPPA kernels while estimating coil sensitivities with ESPIRiT An attention mechanism was employed to weigh the importance of different spatial locations in the image during the reconstruction process This attention mechanism improved the models ability to capture the fine details of the brain anatomy leading to the high SSIM score Moving on to the 8x track the three leading teams AIRS Medical ATB and Neurospin achieved lower SSIM values compared to the 4x track However the SSIM values were still in the acceptable range with values ranging from 0942 to 0952 for the T1 T1POST T2 and FLAIR sequences averaged AIRS Medical achieved the highest SSIM values for the T1 and T1POST sequences with SSIM values of 0953 and 0963 respectively ATB and Neurospin achieved slightly lower SSIM values for these sequences The T2 sequence had similar results with AIRS Medical achieving the highest SSIM value Once again the FLAIR sequence had the lowest SSIM values for all three teams with AIRS Medical achieving the highest value of 0918 followed by ATB with 0905 and Neurospin with 0898 This highlights the difficulty of reconstructing the FLAIR sequence in both the 4x and 8x tracks Overall the results of the 2020 fastMRI challenge demonstrate the effectiveness of deep learning methods in MRI reconstruction The leading teams achieved high SSIM values for most sequences with the FLAIR sequence being the most challenging AIRS won all three tracks and had the largest model However large models were not always better with ATB having a model with similar performance to Neurospin despite having 87 model used a normalization routine to get the data into a consistent format for all coil configurations as well as being the only team to use a GRAPPA reconstruction as the initialization Neural networks serve as the basis for modern artificial intelligence and machine learning These computational models are influenced by the structure and function of biological neural systems and they enable highly complex tasks by layering and interconnecting artificial neurons Neural networks have found use in numerous disciplines including computer vision natural language processing and robotics among others In the 1940s Warren McCulloch and Walter Pitts proposed a simplified computational model of a biological neuron called the McCullochPitts neuron in Figure 31 In the decades that followed Frank Rosenblatt introduced the perceptron the first trainable neural network model capable of classifying linearly distinct patterns The development of the backpropagation algorithm in the 1980s allowed for the efficient training of multilayer perceptrons signifying a significant milestone in the field of neural networks A Concise History of Neural Networks In recent times the field of neural network research has experienced significant progress particularly in the 21st century This progress has been characterized by remarkable advancements in deep learning techniques which have emerged as a dominant force in the domains of artificial intelligence AI and machine learning ML applications The advancement of contemporary hardware particularly graphics processing units GPUs has enabled the training of neural networks that are progressively intricate and deep As a result it can be observed that these neural networks have attained remarkable levels of performance in diverse domains such as image recognition language translation and game playing A neural network is a computational model that consists of interconnected artificial neurons which are also referred to as nodes or units These nodes are organized into layers with each layer performing a specific function in the networks overall computation The neural networks architecture is designed to mimic the structure and function of the human brain allowing it to learn and make predictions based on input data In the domain of neural networks it is widely recognized that there exist three fundamental categories of layers namely the input layer the hidden layer and the output layer Figure 32 These layers are integral components of the neural network architecture and are responsible for processing and transmitting information throughout the network The input layer serves as the initial point of entry for data while the hidden layers process the information through a series of mathematical operations ultimately leading to the output layer which produces the final result or prediction Each individual neuron within a given layer is intricately linked to every other neuron in the subsequent layer through a complex network of weighted connections The weights in a neural network are indicative of the degree of connectivity between neurons and their respective magnitudes are acquired through the process of training The processing of incoming data by neurons is accomplished through the application of an activation function which serves to determine the output of the neuron based on the weighted sum of its inputs Examples of such activation functions include the sigmoid and rectified linear unit ReLU The activation function serves the purpose of introducing nonlinearity into the model thereby enabling the neural network to learn complex and nonlinear relationships that may exist within the data This is achieved by applying a mathematical function to the output of each neuron in the network which allows for the transformation of the input signal into a more expressive and informative representation This step is crucial for the neural network to effectively capture the intricate and nuanced patterns that may exist within the data which may not be possible with a linear model Therefore the activation function plays an essential part in the success of the neural network in learning and making accurate predictions Several types of neural networks have been developed to address different problem domains Feedforward Neural Networks FNNs are a type of artificial neural network where the flow of data is unidirectional moving from the input layer through the hidden layers and ultimately to the output layer This architecture is characterized by the absence of feedback connections which means that the output of each layer is only connected to the subsequent layer The input layer receives the raw data which is then processed by the hidden layers using a series of mathematical transformations Finally the output layer produces the networks prediction or classification based on the input data This unidirectional flow of information is a defining feature of FNNs and is what distinguishes them from other types of neural networks Recurrent Neural Networks RNNs are a type of neural network architecture that possess connections that form directed cycles enabling them to retain and manipulate information from preceding time steps This unique characteristic of RNNs allows them to effectively model sequential data such as natural language speech and time series data By leveraging the information from previous time steps RNNs can capture the temporal dependencies and patterns that exist within the data making them a powerful tool for a wide range of applications in machine learning and artificial intelligence The architectural design under consideration is deemed highly appropriate for sequencetosequence tasks which encompass a wide range of applications including but not limited to time series prediction and language modelling Convolutional Neural Networks CNNs are a class of deep neural networks that employ convolutional layers to extract and learn spatial hierarchies from input data This makes them particularly wellsuited for tasks that involve processing images or other gridlike data By leveraging the power of convolutional layers CNNs are able to effectively capture and represent the underlying patterns and structures present in the input data As a result they have become a popular and widelyused approach for a variety of computer vision tasks including image classification object detection and semantic segmentation among others Convolutional neural networks CNNs have been widely employed in various applications including but not limited to image recognition object detection and segmentation Segmentation neural networks refer to a class of specialized computational architectures that are specifically designed to partition images into meaningful and distinct segments or regions The primary objective of these networks is to accurately identify and classify the various components of an image based on their unique characteristics and features This process involves the use of advanced algorithms and techniques that enable the network to analyze and interpret the visual information contained within the image and to generate precise and reliable segmentations that can be used for a wide range of applications The objective of these networks is to allocate a categorical label to every individual pixel present in the input image thereby generating a segmented output The process of image segmentation holds paramount importance in a multitude of applications including but not limited to autonomous vehicles medical imaging and scene understanding Its significance lies in the ability to partition an image into distinct and meaningful regions thereby facilitating the extraction of relevant information Overall segmentation neural networks represent a powerful and versatile tool for image analysis and processing with significant potential for further development and refinement in the future The Fully Convolutional Network FCN is considered one of the earliest architectures used for segmentation Unlike traditional neural networks FCN is entirely made up of fully connected layers and thus can process input images of any size Its unique architecture enables it to generate dense pixelwise predictions making it a popular choice for image segmentation However Convolutional Neural Networks CNNs are a type of neural network that can be repurposed for segmentation tasks by replacing fully connected layers with convolutional ones This modification enables the network to process images of varying sizes and produce dense pixelwise outputs While a typical CNN provides one prediction for each input image by gradually decreasing the representation size along a contracting path an FCN follows an expansive path and uses the data from the contracting path to provide one prediction per image pixel in segmentation tasks These approaches have proven to be highly effective in image recognition tasks as it allows for the efficient analysis of complex visual data Various other architectural models have been devised to enhance the performance of Fully Convolutional Networks FCNs Among these models are UNet and DeepLab These models have been developed with the aim of addressing the limitations of FCNs and improving their efficacy in various applications The UNet architecture has gained significant popularity in the field of biomedical image segmentation due to its utilization of a symmetric encoderdecoder structure which is augmented with skip connections This design choice has been shown to enhance the localization of objects within the image and facilitate the recovery of finegrained details In contrast DeepLab is a convolutional neural network architecture that integrates atrous convolutions and spatial pyramid pooling techniques to effectively capture multiscale contextual information This approach has resulted in great performances on various segmentation benchmarks VarNet is a neural network architecture for variational inference in probabilistic models This approach leverages the power of neural networks to enable efficient and effective modelling of complex distributions VarNet is a promising development in the field of machine learning as it has the potential to significantly enhance the accuracy and efficiency of probabilistic modelling tasks Despite not being specifically designed for segmentation tasks it presents itself as a noteworthy alternative to conventional models The VarNet model is comprised of a series of normalizing flow transformations that are subsequently followed by a base distribution which is typically a Gaussian distribution Normalizing flows represent a class of generative models that operate by transforming a basic probability distribution such as a Gaussian distribution into a more intricate distribution through the application of a sequence of invertible transformations This approach enables the generation of complex distributions that are capable of capturing the underlying structure of the data One of the primary benefits of employing normalizing flows is their ability to facilitate the effective computation of the loglikelihood of the model This is a crucial requirement for probabilistic inference The UNet model developed at the University of Freiburgs Computer Science Department for biomedical image segmentation serves as the baseline provided by Facebook AI for the FastMRI challenge This wellknown convolutional neural network is frequently used in biomedical segmentation tasks and is a safe and reliable option for the task The UNet architecture is similar to that of the Fully Convolutional Network with an Encoder extracting features and a Decoder building the segmentation map The Encoder which is a contracting part consists of two 3x3 convolutions followed by a maxpooling operation with a pooling size of 2x2 and stride of 2 which is repeated four times while doubling the number of filters in the convolutional layers after each downsampling In more detail a convolutional layer creates a set of output feature maps by applying a number of filters to the input data Each filter extracts a specific feature from the input data by sliding over the input data during the convolution operation and determining at each position the dot product between the filter and the input This operation produces a feature map that shows the locations of each feature in the input data On the other hand the max pooling operation decreases the dimensionality of images by lowering the number of pixels in the output from the previous convolutional layer When using max pooling the input image is divided into a number of nonoverlapping rectangles and the maximum value of each rectangle is then calculated The input images size is decreased through this operation while its most crucial components are kept A pooling layers main goal is to gather features from maps produced by the convolution over the image Average pooling and maximum pooling are two popular pooling techniques that summarize the average presence of a feature and the most activated presence of a feature respectively The Decoder has a similar sequence of upsampling and two convolution operations with the inputs in the first convolutions taking into account both the previous blocks activation and the activations from the corresponding block in the Encoder This sequence is also repeated four times with the number of filters divided by two at each stage followed by a 1x1 convolution operation to generate the final segmentation map without sacrificing spatial resolution Figure 34 Vidushi Bhatia Unet Implementation from Scratch using TensorFlow The symmetric design of the UNet architecture allows for a direct comparison of the Encoder and Decoder blocks as well as the incorporation of skip connections that connect the output of an Encoder block to the corresponding Decoder block Figure 35 Skip connections in particular can serve to prevent the neural network from becoming trapped in a local minimum by providing an alternative pathway for the gradient to flow The UNet model has been modified and adapted for a variety of tasks such as image denoising superresolution and imagetoimage translation demonstrating its effectiveness Its popularity and success have resulted in numerous followup studies and variations including changes to the Encoder and Decoder blocks the addition of attention mechanisms and the use of deeper and wider network architectures Moreover its versatility with its adaptability to various tasks provided me with the opportunity to incorporate new features to improve the models performance as will be evidenced in the following section The proposed neural network which aims to increase the accuracy and quality of the results is a modified version of the UNet architecture by V Lievin The primary components of the UNet like the encoderdecoder structure are still present To retain more data from the dataset and as a result produce higheraccuracy results additional features are included in this architecture One of the key features of the proposed network is the use of Dilated Convolution blocks In contrast to conventional convolutions these convolutions also include a dilation factor that controls the spacing between the kernel points Dilated convolution operations expand the filter by introducing gaps between the filter values the size of the gaps is determined by the dilation rate which is a hyperparameter which can be changed arbitrarily By setting the dilation rate to 1 we would perform a regular convolution Because the filter is still the same size but has gaps between the values the dilation rate effectively expands the receptive field of the filter without increasing the number of parameters This can be useful in situations where a larger receptive field is needed but increasing the size of the filter would lead to an increase in the number of parameters and computational complexity Dilated convolutions are able to capture a wider context than standard convolutions because the spacing between the kernel points is increased They are used in the ResUNet architecture to accurately segment medical images by capturing both local and global features of the input image They require two tensors produced by the Convolutional Encoder as input and are made up of the BatchNorm ReLu and Dropout functions A tensor with the dimensions 64x256x3x3 is the output of the Dilated Convolution block and is sent to the Convolutional Decoder Dilated convolutions have been used successfully in various applications such as semantic segmentation where a larger context is needed to classify each pixel and audio processing where the network needs to learn patterns with longer time dependencies The Residual Block is yet another crucial component of the proposed network introduced as part of the ResNet architecture A stack of layers called a residual block is set up so that each layer’s output is added to a layer further down the stack They are in other words particular skip connection blocks that learn residual functions with reference to the layer inputs instead of learning unreferenced functions More formally we let the stacked nonlinear layers fit another mapping of Fx Hx x that denotes the desired underlying mapping as Hx It transforms the original mapping into Fx x The term “Residual Block” refers to how Fx behaves like a residual The idea is that optimizing the residual mapping is simpler than optimizing the original unreferenced mapping In the most extreme case fitting an identity mapping by a stack of nonlinear layers would be more difficult than pushing the residual to zero if an identity mapping were optimal This method can help to alleviate the issue of vanishing gradients during training by allowing information to flow from the first to the last layers and then summing the processed data with the trained data The designed architecture blends techniques to better handle the residual data and processed data allowing for more optimized information transmission with the aim of retaining more data from the dataset and thus producing more accurate results The structure of my network as computed by TensorBoard is illustrated in Figure 37 This study is based on the official FastMRI dataset provided by the radiology department at NYU The said dataset includes MRI scans of the knee and brain that were performed using singlecoil and multicoil methods respectively However our research is primarily focused on multicoil brain images The dataset consists of 6970 fully sampled brain MRIs that have been deidentified in accordance with HIPAA regulations by NYU Langone Health captured on 3 and 15 Tesla magnets The images are divided into 3001 at 15T and 3969 at 3T Axial T1 Axial T1 weighted T2 weighted FLAIR and T1 weighted with contrast agent T1 POST are the sequences that can be found in the raw dataset Each one of them is used to highlight certain aspects of the picture T2 weighted sequences are primarily used to identify pathological changes in neural tissue whereas T1 weighted sequences are helpful for examining the normal anatomy of the brain While T1 weighted is referred to as the T1 time measured in the absence of a contrast agent postcontrast T1 is time measured after the application of gadolinium is used to calculate extracellular volume ECV a surrogate parameter for the extracellular matrix FLAIR is a particular inversion recovery sequence that removes cerebrospinal fluid signal from the resulting images but has a long inversion time Grey matter is brighter than white matter in brain tissue on FLAIR images which are similar to T2 weighted images but cerebrospinal fluid is dark rather than bright Its worth mentioning that some T1weighted acquisitions include contrast materials Each file contains around 30 slices of fully sampled images from the MRI samples and is stored in the Hierarchical Data Format HDF The dataset consists of five distinct components training validation multicoil test multicoil challenge and singlecoil challenge which were randomly allocated by the NYU Health department This systematic organization allows for the evaluation and comparison of various MRI reconstruction algorithms contributing to the overarching goal of the FastMRI project Field Strength 15T 3T Total T1 375 407 782 T1 POST 849 641 1490 T2 1651 2515 4166 FLAIR 126 406 532 Generalized Autocalibrating Partially Parallel Acquisitions GRAPPA is an automatic coilbycoil reconstruction technique that poses parallel imaging reconstruction as an interpolation problem GRAPPA is based on the principle of partially acquiring data in kspace the spatial frequency domain of the MRI signal and reconstructing the missing information using a linear combination of adjacent kspace data points GRAPPA weights which are determined during the calibration phase are utilized to model the relationship between the acquired data and the missing data The calibration phase works by acquiring a fully sampled region in the centre of the kspace known as the autocalibration signal ACS The ACS is applied to the undersampled data to reconstruct the missing kspace lines In order to estimate the GRAPPA weights a system of linear equations is developed by correlating the acquired ACS data with the missing target data Solving this system of equations using least squares or other optimization techniques yields the weights Then GRAPPA weights are applied to the acquired undersampled data during the reconstruction phase to predict the missing kspace lines The inverse Fourier transform is then applied to the reconstructed kspace to produce the final image Consider S to be the image in the kspace domain computed using the Fourier Transform from the original image data The kspace data acquired can be represented as D S where D represents the acquired kspace data C represents the coil sensitivity map in kspace and is the convolution operation GRAPPA can estimate the missing kspace data Sm using a linear combination of neighboring acquired data points Sm wi D i where wi represents the GRAPPA weights N represents the number of neighboring points and i represents the kspace coordinates of the neighboring points Griswold MA Jakob PM Heidemann RM Nittka M Jellus V Wang J Kiefer B and Haase A 2002 Generalized autocalibrating partially parallel acquisitions GRAPPA Based on the paper by Griswold et al the implementation takes as input the masked kspace tensor and the randomly computed mask that simulates undersampled kspace data After applying the GRAPPA algorithm as you can see from the code in Code 41 the function returns the preprocessed masked kspace tensor of the MR image I implemented this function as the initial algorithm to preprocess the data before feeding the images into the neural network A function is defined within the code to compute the lowfrequency line indices in the kspace The tensor is a multicoil masked input kspace tensor with the shape num has the same dimensions as the input The mask tensor is the mask applied to shape 1 1 cols 1 The function calculates the indices of the lowfrequency lines in kspace by finding the first and last nonmasked lines in the middle of kspace These lowfrequency lines are subsequently used as the GRAPPA algorithms calibration region Then the variable stores the number of lowfrequency lines in the kspace and the variable computes the padding necessary to center the lowfrequency lines in the mask tensor The variable stores the calibration region derived from the masked kspace tensor As inputs to the grappa function are the masked kspace tensor and the calibration region The parameter is set to 5 5 and is set to 0 to indicate that the coil axis is the first axis of the input tensors The tensor is obtained by using the function to convert the GRAPPA algorithms output which will be computed from the library to a tensor The final return value of the function is the tensor The following images depict the process of selecting a slice of the brain from an MR file a as the ground truth goal and then masking this image using an 4x and 8x acceleration factor to simulate undersampled data b The slice is then reconstructed using the grappa algorithm which takes around 6 seconds resulting in the reconstructed image c As shown in Figure 43 in the case of the 4x acceleration factor the SSIM metric varies between 074 for the undersampled image and the ground truth image indicating significant data loss due to masking However our preprocessing algorithm improves the SSIM value to 077 resulting in a more accurate and visually pleasing image for further analysis In the other case with the image even more masked the SSIM values drop to 060 with the acceleration factor set to 8x Using the GRAPPA algorithm the quality represented by SSIM increases to 068 Nevertheless for specialists an image that is still degraded may not be suitable for analysis This motivated us to introduce another technique to further process the image before feeding it into the main neural network def applygrappamaskedkspace mask def getlowfrequencylinesmask l r maskshape 2 while mask r 1 while mask l 1 return l 1 r l r getlowfrequencylinesmask numlowfreqs r l pad maskshape numlowfreqs 1 2 calib maskedkspaceclone preprocessedmaskedkspace grappatensortocomplexnpmaskedkspace tensortocomplexnpcalib kernelsize5 5 coilaxis0 return totensorpreprocessedmaskedkspace Prior to the introduction of the ESPIRiT SENSE and GRAPPA were the most frequently used parallel MRI reconstruction techniques SENSE is a coilbycoil reconstruction method that uses fully sampled reference data to estimate the coil sensitivities which are then used to unfold the aliased images Separate coil sensitivity maps are necessary for SENSE though they can be timeconsuming to acquire and risk including errors if not estimated correctly GRAPPA on the other hand is a datadriven approach that uses the variations in coil sensitivity to infer the missing kspace data from nearby acquired data points GRAPPA relies on the regularity of the sampled kspace data rather than explicit knowledge of the coil sensitivities When used alone GRAPPA may experience noise amplification and limited accuracy in highly undersampled data By combining the advantages of SENSE and GRAPPA ESPIRiT is a novel strategy that fills the gap between them The central concept of ESPIRiT is to simultaneously estimate the coil sensitivity maps and the missing kspace data using an eigenvalue decomposition method This is accomplished by rewriting the parallel MRI problem as an eigenvector problem where the coil sensitivities are represented by the eigenvectors with the largest eigenvalues and the missing kspace data is encoded by the eigenvectors with the smallest eigenvalues The foundation of ESPIRiT is the idea of subspacebased methods which have been extensively applied to image and signal processing The calibration matrix for the ESPIRiT method is built from the acquired kspace data which captures the inherent correlations between various coil channels and the spatial organization of the coil sensitivities C H where n is the number of coils H is the Hermitian transpose and yi denotes the kspace data acquired by the ith coil The underlying structure of the coil sensitivities and the missing kspace data are then revealed by decomposing the calibration matrix into its eigenvalues and eigenvectors using the following equation C U VH where U and V are unitary matrices and is a diagonal matrix containing the eigenvalues of C The coil sensitivity maps are created using the eigenvectors linked to the largest eigenvalues and they are then used to unfold the aliased images similarly to SENSE S Utilizing the innate structure of the acquired data the eigenvectors linked to the smallest eigenvalues are used to estimate the missing kspace data in a GRAPPAlike manner y H SH where SH is the conjugate transpose of the estimated sensitivity maps The unfolded images and the estimated missing kspace data are then combined with an inverse Fourier Transform to create the reconstructed images x F S y y where F denotes the inverse Fourier Transform and y is the unfolded kspace data obtained using the estimated sensitivity maps The map of all Gs eigenvalues and eigenvectors is shown in Figure 45 For data from an eightchannel headcoil G has been calculated as the Fourier transform of the reconstruction operator W using a 24 x 24 kspace calibration region and a 6 x 6 kernel size Eigenvalues are arranged on the left in order of decreasing magnitude Where there is signal in the image Eigenvalues equal to one are visible Right The eigenvector maps magnitude and phase for each eigenvalue at all spatial locations The eigenvectors that correspond to eigenvalues of 1 seem to be sensitivity maps as expected The sensitivities magnitude and phase closely match the bottom rows individual coil images magnitude and phase The eigenvectors are defined only up to multiplication with an arbitrary complex number Due to this each locations eigenvector norm is normalized to one and the 8th channel is used as a reference with zero phase Original Paper ESPIRiT has a number of benefits over conventional parallel MRI techniques The first benefit is that it offers a uniform framework for parallel MRI reconstruction that combines the advantages of both GRAPPA and SENSE Second it simplifies the reconstruction process and lowers computational complexity by not requiring separate estimation of the coil sensitivity maps and the missing kspace data Thirdly because the eigenvalue decomposition method is less sensitive to noise and errors in the acquired data it is inherently robust to noise and artefacts Original Paper By introducing noise to fullysampled data noise levels 1 10 and 20 it has been possible to examine the impact of noise on the calibration of the sensitivity maps In the first column of the Figure 46 the images that are fully sampled and correspond to the first channel at various noise levels In the second column is shown the first channels estimated sensitivity map as determined by ESPIRiT calibration The projection of the fully sampled original data scaled by a factor of 5 onto the nullspace determined by the sensitivities is shown in the third column The results indicate that ESPIRiT working alone without the intervention of neural networks or other algorithms produces more accurate results than GRAPPA Another illustration of the variations between undersampled MRI data reconstruction using various algorithms is shown in Figure 47 The residual signal is reduced to its minimum by using the NLINV algorithm and ESPIRiT directly on the slice but it is not completely reduced by SENSE NLINV is another reconstruction algorithm used to produce highquality images from MRI data that is highly undersampled It is a nonlinear inverse reconstruction method that involves iteratively solving a nonlinear problem to estimate the underlying image from the acquired kspace data using the idea of regularized nonlinear inversion Regarding the specific implementation of ESPIRiT Code 42 the function takes in the kspace data and reconstructed image as input and returns the combined image It first performs a few transformations of the image axes and then creates and runs the SigPy implementation of the ESPIRiT calibration function with the kspace data as the only input This process may take a few seconds and will return ESPIRiT coil sensitivity maps of the same size as the kspace data The function then combines the coil sensitivity maps with the image data using elementwise multiplication and summation along the coil dimension The idea behind coil combination is to weight each coil image by its corresponding sensitivity map so that the resulting combined image has a higher signaltonoise ratio SNR and reduced artefacts def standardizemulticoilimagekspace image Permute kspace data so that the coil dimension is the last kspaceperm npmoveaxiskspace 0 2 Add a batch dimension to kspace data kspaceperm npexpanddimskspaceperm axis0 Create an ESPIRiT calibration object using the kspace data espirit mriappEspiritCalibkspace Compute the ESPIRiT operator using the calibration object S espiritrun Combine the coil images using the ESPIRiT operator Mcomb npsumnpmultiplynpconjS imageaxis0 Add a batch dimension to the combined image and return it Mcomb npexpanddimsMcomb axis0 return Mcomb In Code 43 is shown a fundamental class that applies both GRAPPA and ESPIRiT transformations to the data before feeding it to the neural network The arguments of this class are the input kspace of shape the mask to apply on the data the target image ground truth a few attributes related to the h5 image the file name of the image and the serial number of the slice It returns a tuple containing the zerofilled processed image the reconstruction target the mean and standard deviations used for normalization the filename and the slice number Specifically the kspace data is first converted to a PyTorch tensor using the function Then if a mask function was provided a mask is applied to the kspace data using the function Next GRAPPA is applied to try to reconstruct the masked image Since GRAPPA works in the kspace but ESPIRiT works with both the kspace data and the zerofilled solution real image data the Inverse Fourier Transform is used to get the zerofilled solution which is then passed as input to the function This function returns the calibrated and reconstructed image follwing ESPIRiT algorithm Note that the function takes complex Numpy arrays as input so both tensors are first transformed into Numpy arrays After this a few minor transformations are applied to the data such as cropping the data to the correct size based on the target image and taking the absolute value of the data Since the challenge is multicoil RootSumofSquares is applied to get the final image with all the coils in one image Finally the tensor is normalized and the final tuple is returned class UnetDataTransformGrappa def call self kspace mask target attrs fname slicenum transform the input kspace into a Tensor kspacetorch totensorkspace apply mask maskedkspace mask applymaskkspacetorch selfmaskfunc seedseed apply Grappa maskedkspace applygrappamaskedkspace mask Apply inverse Fourier transform to get the actual image image fastmriifft2cmaskedkspace apply ESPIRiT image standardizemulticoilimage tensortocomplexnpmaskedkspace tensortocomplexnpimage Transform the resulting image into a Tensor image totensorimage Returns the tuple with processed data return UnetSample imageimage targettargettorch meanmean stdstd fnamefname slicenumslicenum maxvaluemaxvalue The training was conducted entirely on a single Tesla V100SXM2 with 32GB of memory which was provided to us by the Istituto Nazionale di Fisica Nucleare Italian National Institute for Nuclear Physics and took around a week to complete for each training instance 4x and 8x The difference between these two training cases is that for the 4x track I set the acceleration factor to 4 during data masking while for the 8x track I set it to 8 Consequently the entire dataset was masked with the respective acceleration factor prior to the application of preprocessing algorithms and the start of neural network training The model was trained using SSIM as the loss function for both tracks since it is the main metric that I aimed to maximize in this project To achieve this I set the loss function to 1SSIM A mechanism was implemented to save the checkpoints of the model with the highest SSIM values over the validation set which was used as a measure of the models performance on the validation data The acceleration factor R is defined as the ratio of the amount of data required for a fully sampled image to the amount collected in an accelerated acquisition This implies that when using a 4x acceleration factor only 75 The 4x track was easier to train and the neural network equipped with the preprocessing methods had no difficulty in converging to a minimum loss result A learning rate of 10 was used for the first 40 epochs of the training process After 40 epochs the learning rate was decreased to 10 to help the model converge to a better minimum This gradual decrease in the learning rate is a common technique known as learning rate decay and it is often used to improve the performance of neural networks during training Figure 53 displays the progression of the loss function during the initial training phase The three lowest loss function values are highlighted with an alltime low of 003225 It is noteworthy that these values were obtained directly from the training data and therefore their attainment is relatively straightforward Despite this the corresponding SSIM values for these optimal loss function values are remarkable reaching an impressive value of 096775 The validation loss graph Figure 54 provides a more comprehensive illustration of the learning evolution throughout the 50 epochs The models performance improves rapidly in the first few epochs attributable to the high learning rate but then gradually stagnates and cannot achieve lower values for a prolonged period Around the end of the training the optimal validation loss value of 010537 is the best obtained The metrics shown in Figures 55 56 and 57 are coherent as the best results are got in the final epochs of the training starting from the 40th to the 50th epoch In particular the best result for each metric is got at the 43rd epoch for the PSNR 375703 and at the 46th epoch for both NMSE and SSIM respectively 001446 and 09284 On the following pages there are figures showing MR images generated during the architecture training with their corresponding SSIM values displayed to track the loss metric The actual images are on the left while the error compared to the ground truth is on the right In a later picture 512 the corresponding ground truth images are presented which are the actual images the model aims to generate and from which the SSIM values are computed In the 8x track the results were consistently worse than in the previous track due to the data being deeply undersampled with only around 60 One important modification was the implementation of an algorithm called developed by the Lightning Team This algorithm tests different learning rates and selects the most appropriate one after a few steps of training in our case the learning rate that was preferred was 10 This approach was chosen after careful consideration of the previous training in the 4x track as highweight updates could be problematic with such undersampled data In addition to the algorithm weight decay and dropout probability were introduced in this track to further improve the models performance Weight decay is a regularization technique that aims to prevent overfitting by adding a penalty term to the loss function that encourages the model to have smaller weight values This is because larger weights can lead to overfitting as they may cause the model to become too specialized to the training data and not generalize well to new data Overfitting is a common phenomenon in machine learning that we try to avoid which occurs when a model is excessively trained on a particular dataset leading to the model learning the idiosyncratic features or noise in the data instead of the underlying patterns Consequently such a model may perform exceptionally well on the training data but may not generalize well to new unseen data Dropout is another technique used to prevent overfitting by randomly dropping out some of the neurons during training This means that some of the neurons in the model will be ignored during each training iteration which forces the model to learn more robust and generalizable features Dropout can be thought of as a way to prevent the model from relying too heavily on any one feature or combination of features which can lead to overfitting These modifications were aimed at improving the models ability to handle the challenges posed by the deeply undersampled data and ultimately produce higherquality results I set both of these values to a standard value specifically dropout probability was set to 05 and weight decay to 10 Moreover I opted for 70 epochs in this run for many reasons First increasing the acceleration factor from 4x to 8x required more training time to capture the finer details and also the data has more complex features and patterns that the architecture needs to decrypt and that require additional training time to learn Finally using a larger number of epochs helped the model to gradually refine its understanding of the data over time with a lower learning rate than before In pictures 513 514 and 515 is shown a random slice of MR data that has been processed with an 8x accelerated mask Figure 516 displays the progression of the loss function during the 70 epochs of the training The values shown are computed on the training dataset and for this motivation many impressive values are reached The best result is 004693 computed around half of the training process The validation loss graph Figure 517 provides a crucial overview of the models learning progress during the 70 epochs With a lower learning rate the models performance steadily improves in the right direction throughout the training process By the 40th epoch a stable value is reached indicating that the model has reached its optimal performance Then it slightly improves its SSIM value over the final epochs reaching a minimum of 012511 at the 65th epoch The metrics in Figure 518 519 and 520 confirm what we observed in the previous graphs with valid results achieved across all metrics by the end of the training process The maximum SSIM achieved was 08984 which is lower than the previous track but still a remarkable result considering how challenging it is to reconstruct images from only 60 In the following figures I present some shots of the same slices of MR data taken every few epochs during the 70epoch training process for a total of four different images and five shots for every image It is noticeable that the SSIM tends to increase over time as expected However there are occasional dips in SSIM and the results are consistently lower than those of the previous 4x track In this section I will discuss the results of my work on accelerated MRI reconstruction I addressed this problem by developing a neural networkbased approach and incorporating two powerful preprocessing methods To evaluate the effectiveness of my approach I conducted experiments at two different acceleration factors 4x and 8x For the 4x acceleration factor my neural network was able to converge to a minimum loss result effectively I employed a learning rate of 10 for the first 40 epochs followed by a decrease to 10 to facilitate convergence to a better minimum I observed that the lowest loss function value was 003225 and the corresponding SSIM reached an impressive value of 096775 on the training split while the average validation set score reached 09284 After examining the best reconstruction of image file 15800 in the 4x track we zoomed in on approximately the same region with different levels of magnification Figure 526 While we observed that a few details were missing overall the image quality was great Similarly in file 9605 as shown in Figure 527 the image quality is generally appreciable however there are some regions that appear blurred When examining Figure 528 it becomes apparent that there is an imprecision in the reconstruction Specifically the brain image is not demarcated correctly making it easy to spot few errors The validation loss graph provided a comprehensive illustration of the learning evolution throughout the 50 epochs The models performance improved rapidly in the first few epochs thanks to the high learning rate Toward the end of the training the optimal validation loss value of 010537 was the best obtained The best results for each metric were achieved during the final epochs of the training including a PSNR of 375703 at the 43rd epoch and NMSE and SSIM values of 001446 and 09284 respectively at the 46th epoch These results demonstrate the effectiveness of our model for the 4x acceleration factor For the 8x acceleration factor track we faced a more challenging scenario due to the deeper undersampling of the data with only around 60 We increased the number of training epochs to 70 for the 8x track which allowed the model to capture finer details and complex patterns in the data The best loss function value achieved during training was 004693 and the validation loss graph showed a steady improvement in performance throughout the training process The model reached a stable value by the 40th epoch and achieved a minimum validation loss of 012511 at the 65th epoch The metrics further confirmed the effectiveness of our approach for the 8x acceleration factor with a maximum SSIM of 08984 achieved by the end of the training process Although this value is lower than that obtained for the 4x track it is still a remarkable result given the challenge of reconstructing images from only a small part of the available data By examining two specific files and zooming in 2x and 3x on a slice Figures 529 to 531 we can compare the images to the ground truth and analyze them We can observe that multiple regions of the image are too blurred to be useful In this 8x track the data was deeply undersampled leading to a reconstruction that has limited practical value for specialists While the result is exceptional considering how undersampled the data was these figures would not be useful to radiologists as they lack details and exhibit blurry brain structures In the next table a summary of the teams results along with our architecture for both 4x and 8x tracks Team 4x Track 8x Track Average AIRS Medical 0964 0952 0958 ATB 0960 0944 0952 Neurospin 0959 0942 09505 This table shows a summary of SSIM Structural Similarity Index results for each team in the FastMRI 2020 competition The table indicates that the proposed architecture represented by the Ours team obtained slightly lower SSIM values compared to the top three teams AIRS Medical ATB and Neurospin in both the 4x and 8x tracks with the Average column displaying the average SSIM score across both tracks The Ours team had the lowest average SSIM score compared to the other teams in the FastMRI 2020 competition To get a better idea of how the performance of my architecture compared to the other teams I calculated the percentual difference between the SSIM score of the ours team and the SSIM scores of each of the other teams The percentual difference between our research and the team with the highest SSIM score AIRS Medical was 307 Figure 532 depicts a graph that displays the scores of the other teams in the competition sidebyside with the addition of my teams result to the graph in red Based on the given results the proposed architecture would rank just after the 6th team in the 4x track and just after the 4th team in the 8x track indicating great performance in general I also compared all the other metrics obtained with those obtained by the other teams and they are all coherent with the SSIM Our architecture is just after the 6th team in 4x and after the 4th team in the other metrics such as NMSE and PSNR According to several interviewed radiologists the images generated at a 4x acceleration factor are comparable to traditional scans and are suitable and usable for diagnostic purposes in a hospital setting However these experts did note that there were some artefacts present in T1POST images that may impact the accuracy of certain diagnoses In the case of the 8x track the radiologists were more critical in their feedback Many of them stated that none of the submitted images were deemed acceptable The radiologists were influenced by the presence of hallucinations as seen in Figure 533 which are considered unacceptable These hallucinations were particularly problematic when they mimicked normal structures that were either nonexistent or actually abnormal Despite having high SSIM scores these images were not optimized in terms of the presence of hallucinations This suggests that the optimization metric used may not be appropriate for detecting these features In reconstructions made by my architecture I did not observe any artifacts of this kind Moreover the results from the specific sequences are similar to ours as all teams including ours had the lowest results in the FLAIR sequence indicating that it was the most challenging to reconstruct Feedback was received from both participating and nonparticipating teams with the second stating that they were unable to participate due to the high computational and storage requirements In the future researchers suggested that it would be beneficial to lower the barriers to entry especially for academic groups that may have innovative methods but limited computing or storage resources Another feedback received was regarding the use of SSIM as the primary metric for evaluating the images which tends to promote smoothing rather than relying on radiologist interpretation Both of these issues are of fundamental importance and require further investigation In conclusion our work demonstrates the potential of deep learning techniques for accelerated MRI reconstruction Our neural networkbased approach was able to effectively reconstruct highquality images from undersampled kspace data but the results at high acceleration factors 8x were less operable by specialists due to their blurry and not detailed quality After comparing my images and scores to those of other teams it became apparent that the issues observed were common to their algorithms as well This observation suggests that the problem may be inherent to the task itself rather than specific to my approach The results obtained for both the 4x and 8x acceleration factors showcase the effectiveness of our method and its ability to handle the challenges posed by undersampled data In conclusion this thesis has presented novel neural network architectures designed to address the challenges associated with reconstructing highly accelerated MRI data We have developed a ResidualUNet capable of handling complex data in conjunction with stateoftheart preprocessing methods namely ESPIRiT eigenvalue approach to autocalibrating parallel MRI and GRAPPA Generalized autocalibrating partially parallel acquisitions The successful implementation of these architectures demonstrates the potential of neural networks to enhance the computational efficiency of MR image reconstruction To assess the effectiveness of our approach we trained the proposed architecture on the NYU MRI dataset using two distinct training instances with two undersampling techniques reducing the amount of data acquired by factors of 4 4x and 8 8x respectively The resulting reconstructions were compared to those achieved by teams participating in the FastMRI challenge utilizing wellestablished metrics such as SSIM PSNR and NMSE Our findings indicate that our proposed methodology matches the performance of stateoftheart methods employed by other teams in the FastMRI challenge This contribution adds to the growing body of knowledge surrounding deep learning applications in medical imaging with potential implications for the development of advanced techniques in accelerated MRI reconstruction When radiologists provided feedback on the reconstructed images they reported that for the 4x track there were often no significant differences between the reconstructions and the ground truth and they could work with these images without any issues This suggests that our results would likely be wellreceived by medical professionals in the context of the 4x track However the results from the 8x acceleration factor instance study suggest that further optimization and enhancements are needed to produce higherquality reconstructions for images obtained from deeply undersampled data The lower accuracy results blurred reconstructions and hallucination features observed in the images indicate that these aspects require additional investigation and development as they have not been thoroughly addressed by our work or that of other teams In light of these considerations the algorithms studied have succeeded in significantly increasing the effectiveness of MRI scans by cutting scan times by up to four times while maintaining high image quality These algorithms may increase the availability and affordability of MRI scans which could significantly affect healthcare Future research should explore alternative training parameters or techniques to further improve model performance Potential avenues include different regularization techniques altering the loss function extending training epochs investigating new architectures and ensuring the absence of image artefacts or false features ie hallucinations In summary the findings of this study contribute to the field of MR image reconstruction and hold promise for advancements in medical imaging techniques Desidero ringraziare tutti coloro che hanno contribuito al completamento del mio percorso accademico sia coloro che mi hanno accompagnato da sempre sia quelli che sono arrivati più recentemente nella mia vita Un ringraziamento speciale ai miei amici di sempre Gabri e Ali che mi sopportano e mi supportano dal lontano 2012 Siete stati la costante nella mia vita e non potrei chiedere amici migliori Voglio ringraziare anche tutta la Paula Gvng composta da Angelica Giorgia Roberta Bea Martina nonché le estensioni del cerchio Chiara Arianna e Socci Un grazie di cuore allunico collega di cui ho mai avuto bisogno Adriano che ha commentato la mia tesi esclamando Ma è un nuovo cocktail Un ringraziamento speciale anche ai nuovi arrivati finti atleti ma veri amici Michele Riccardo Flavia e tutti gli altri Siete stati una presenza preziosa durante tutto il mio percorso Grazie per avermi fatto ridere e per avermi assecondato nelle mie idiozie ad atletica condividendo con me tante esperienze indimenticabili Desidero esprimere la mia profonda gratitudine verso RussoAssogna che sono stati per me come una famiglia romana durante tutto il mio percorso Ringrazio di cuore Giulia Marghe Luca Piccolo Luca Grande Paola e Gianluca per avermi accolto a braccia aperte e per avermi fornito un ambiente così caloroso Desidero ringraziare in modo particolare la ragazza che è sempre stata al mio fianco e che ha svolto un ruolo fondamentale nel raggiungimento di questo traguardo Gippa questa laurea magistrale è anche tua perché tu hai sempre saputo incoraggiarmi ascoltarmi e sostenermi anche nei momenti difficili Non riesco a ringraziarti abbastanza per esserti sempre presa cura di me sia nei momenti felici che in quelli difficili Grazie per non esserti mai stancata di me anche dopo settimane insieme 24 ore su 24 Se sono qui oggi lo devo in parte a te e per questo ti sarò sempre grato Infine voglio ringraziare la mia famiglia che è sempre stata presente e non si è mai allontanata Mamma Papà Laura Simone Davide e Beba Grazie al vostro esempio ho trovato la forza di perseverare negli studi nonostante avessi sempre pensato di non essere allaltezza Ora guardando indietro sono felice di dire che ce lho fatta e sono grato per lispirazione che mi avete dato 